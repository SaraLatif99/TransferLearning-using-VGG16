{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning using vgg16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4c7zcLOgm1LMxQOqbZBUC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/megha1906/TransferLearning-using-VGG16/blob/master/Transfer_Learning_using_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzoJOGXqD9TK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b267a26e-df66-49d5-aab3-b7f7f007ca26"
      },
      "source": [
        "from keras.applications import vgg16\n",
        "\n",
        "# MobileNet was designed to work on 224 x 224 pixel input images sizes\n",
        "img_rows, img_cols = 224, 224 \n",
        "\n",
        "# Re-loads the MobileNet model without the top or FC layers\n",
        "vgg = vgg16.VGG16(weights = 'imagenet', \n",
        "                 include_top = False, \n",
        "                 input_shape = (img_rows, img_cols, 3))\n",
        "\n",
        "# Here we freeze the last 4 layers \n",
        "# Layers are set to trainable as True by default\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# Let's print our layers \n",
        "for (i,layer) in enumerate(vgg.layers):\n",
        "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n",
        "    \n",
        " \n",
        "def lw(bottom_model, num_classes):\n",
        "    \"\"\"creates the top or head of the model that will be \n",
        "    placed ontop of the bottom layers\"\"\"\n",
        "\n",
        "    top_model = bottom_model.output\n",
        "    top_model = GlobalAveragePooling2D()(top_model)\n",
        "    top_model = Dense(1024,activation='relu')(top_model)\n",
        "    top_model = Dense(1024,activation='relu')(top_model)\n",
        "    top_model = Dense(512,activation='relu')(top_model)\n",
        "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
        "    return top_model \n",
        "    \n",
        "    \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "# Set our class number to 3 (Young, Middle, Old)\n",
        "num_classes = 2\n",
        "\n",
        "FC_Head = lw(vgg, num_classes)\n",
        "\n",
        "model = Model(inputs = vgg.input, outputs = FC_Head)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "0 InputLayer False\n",
            "1 Conv2D False\n",
            "2 Conv2D False\n",
            "3 MaxPooling2D False\n",
            "4 Conv2D False\n",
            "5 Conv2D False\n",
            "6 MaxPooling2D False\n",
            "7 Conv2D False\n",
            "8 Conv2D False\n",
            "9 Conv2D False\n",
            "10 MaxPooling2D False\n",
            "11 Conv2D False\n",
            "12 Conv2D False\n",
            "13 Conv2D False\n",
            "14 MaxPooling2D False\n",
            "15 Conv2D False\n",
            "16 Conv2D False\n",
            "17 Conv2D False\n",
            "18 MaxPooling2D False\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 16,815,426\n",
            "Trainable params: 2,100,738\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu-9bOmCETU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRYKWdwlEX59",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f0420a77-912e-4bd6-eef1-a2acade02277"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwLWKQpnEjy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9c48d2b0-8449-4816-d1b8-1058b9911b83"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir = '/content/drive/My Drive/photos/photos/train'\n",
        "validation_data_dir = '/content/drive/My Drive/photos/photos/validate'\n",
        "\n",
        "# Let's use some data augmentaiton \n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=45,\n",
        "      width_shift_range=0.3,\n",
        "      height_shift_range=0.3,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        " \n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        " \n",
        "# set our batch size (typically on most mid tier systems we'll use 16-32)\n",
        "batch_size = 32\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 539 images belonging to 2 classes.\n",
            "Found 303 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2jJ0uVoE0tA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "ce8dc733-9b4a-4e0b-b699-700788d7ef0d"
      },
      "source": [
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "                     \n",
        "checkpoint = ModelCheckpoint(\"face recognisation.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0, \n",
        "                          patience = 3,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)\n",
        "\n",
        "# we put our call backs into a callback list\n",
        "callbacks = [earlystop, checkpoint]\n",
        "\n",
        "# We use a very small learning rate \n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = RMSprop(lr = 0.001),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# Enter the number of training and validation samples here\n",
        "nb_train_samples = 108\n",
        "nb_validation_samples = 52\n",
        "\n",
        "# We only train 5 EPOCHS \n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = nb_train_samples // batch_size,\n",
        "    epochs = epochs,\n",
        "    callbacks = callbacks,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = nb_validation_samples // batch_size)\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "6/6 [==============================] - 96s 16s/step - loss: 1.7088 - accuracy: 0.4635 - val_loss: 0.6719 - val_accuracy: 0.5312\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.67187, saving model to face recognisation.h5\n",
            "Epoch 2/5\n",
            "6/6 [==============================] - 91s 15s/step - loss: 0.7186 - accuracy: 0.4740 - val_loss: 0.7069 - val_accuracy: 0.4375\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.67187\n",
            "Epoch 3/5\n",
            "6/6 [==============================] - 74s 12s/step - loss: 0.6796 - accuracy: 0.5348 - val_loss: 1.0478 - val_accuracy: 0.4792\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.67187\n",
            "Epoch 4/5\n",
            "6/6 [==============================] - 4s 662ms/step - loss: 0.7252 - accuracy: 0.5365 - val_loss: 0.6852 - val_accuracy: 0.6456\n",
            "Restoring model weights from the end of the best epoch\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.67187\n",
            "Epoch 00004: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRY44SUYGWwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "classifier = load_model('/content/face recognisation.h5')\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "monkey_breeds_dict = {\"[0]\": \" salman \", \n",
        "                      \"[1]\": \"aamir \"}\n",
        "\n",
        "monkey_breeds_dict_n = {\"n0\": \" salman\", \n",
        "                      \"n1\": \"aamir \"}\n",
        "\n",
        "def draw_test(name, pred, im):\n",
        "    monkey = monkey_breeds_dict[str(pred)]\n",
        "    BLACK = [0,0,0]\n",
        "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
        "    cv2.putText(expanded_image, monkey, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
        "    cv2_imshow(expanded_image)\n",
        "\n",
        "def getRandomImage(path):\n",
        "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
        "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
        "    random_directory = np.random.randint(0,len(folders))\n",
        "    path_class = folders[random_directory]\n",
        "    print(\"Class - \" + monkey_breeds_dict_n[str(path_class)])\n",
        "    file_path = path + path_class\n",
        "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
        "    random_file_index = np.random.randint(0,len(file_names))\n",
        "    image_name = file_names[random_file_index]\n",
        "    return cv2.imread(file_path+\"/\"+image_name)    \n",
        "\n",
        "for i in range(0,10):\n",
        "    input_im = getRandomImage(\"/content/drive/My Drive/photos/photos/validate/\")\n",
        "    input_original = input_im.copy()\n",
        "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
        "    \n",
        "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
        "    input_im = input_im / 255.\n",
        "    input_im = input_im.reshape(1,224,224,3) \n",
        "    \n",
        "    # Get Prediction\n",
        "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
        "    \n",
        "    # Show image with predicted class\n",
        "    draw_test(\"Prediction\", res, input_original) \n",
        "    cv2.waitKey(0)\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}